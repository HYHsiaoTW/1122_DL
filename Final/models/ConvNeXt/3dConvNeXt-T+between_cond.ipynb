{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d45535c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/DL_240319/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import random\n",
    "from pathlib import Path\n",
    "from timm.models.layers import trunc_normal_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f3348da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, file_path, path_prefix=\"\"):\n",
    "        self.path_prefix = path_prefix\n",
    "        full_file_path = path_prefix + file_path\n",
    "        with open(full_file_path, 'r') as file:\n",
    "            data = [line.strip().split() for line in file.readlines()]\n",
    "        \n",
    "        self.cond_label = {cond_label: idx for idx, cond_label in enumerate(set(row[1] for row in data))}\n",
    "        self.sub_label = {sub_label: idx for idx, sub_label in enumerate(set(row[2] for row in data))}\n",
    "        self.files = [(row[0], self.cond_label[row[1]], self.sub_label[row[2]]) for row in data]\n",
    "        random.shuffle(self.files)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, cond_label, sub_label = self.files[idx]\n",
    "        full_img_path = self.path_prefix + img_path\n",
    "        \n",
    "        img = nib.load(full_img_path).get_fdata()\n",
    "        img = np.float32(img)\n",
    "        img = torch.from_numpy(img)\n",
    "        if img.ndim == 4 and img.shape[-1] == 1:\n",
    "            img = img.squeeze(-1)\n",
    "        img = img.unsqueeze(0)\n",
    "        cond_label = torch.tensor(cond_label, dtype=torch.long)\n",
    "        sub_label = torch.tensor(sub_label, dtype=torch.long)\n",
    "        return img, cond_label, sub_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b01669c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, drop_path=0., layer_scale_init_value=1e-6):\n",
    "        super().__init__()\n",
    "        # Depthwise 3D convolution\n",
    "        self.dwconv = nn.Conv3d(dim, dim, kernel_size=7, padding=3, groups=dim)\n",
    "        # Layer normalization for 3D (adjusting for channel dimension)\n",
    "        self.norm = LayerNorm(dim, eps=1e-6)\n",
    "        # Pointwise convolutions using linear layers\n",
    "        self.pwconv1 = nn.Linear(dim, 4 * dim)\n",
    "        self.act = nn.GELU()\n",
    "        self.pwconv2 = nn.Linear(4 * dim, dim)\n",
    "        # Layer scaling if it is utilized\n",
    "        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim)), \n",
    "                                  requires_grad=True) if layer_scale_init_value > 0 else None\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = x\n",
    "        x = self.dwconv(x)\n",
    "        x = x.permute(0, 2, 3, 4, 1)  # Permute to bring channel to last\n",
    "        x = self.norm(x)\n",
    "        x = self.pwconv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pwconv2(x)\n",
    "        if self.gamma is not None:\n",
    "            x = self.gamma * x\n",
    "        x = x.permute(0, 4, 1, 2, 3)  # Permute back to normal\n",
    "\n",
    "        x = input + self.drop_path(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a36bc10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-6, data_format=\"channels_last\"):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(normalized_shape))\n",
    "        self.bias = nn.Parameter(torch.zeros(normalized_shape))\n",
    "        self.eps = eps\n",
    "        self.data_format = data_format\n",
    "        self.normalized_shape = (normalized_shape,)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.data_format == \"channels_last\":\n",
    "            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n",
    "        elif self.data_format == \"channels_first\":\n",
    "            u = x.mean(1, keepdim=True)\n",
    "            s = (x - u).pow(2).mean(1, keepdim=True)\n",
    "            x = (x - u) / torch.sqrt(s + self.eps)\n",
    "            x = self.weight[:, None, None, None] * x + self.bias[:, None, None, None]\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b242307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNeXt(nn.Module):\n",
    "    def __init__(self, in_chans=1, nc_cond=8, \n",
    "                 depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], drop_path_rate=0.,\n",
    "                 layer_scale_init_value=1e-6, head_init_scale=1.):\n",
    "        super().__init__()\n",
    "        # Initial downsampling\n",
    "        self.downsample_layers = nn.ModuleList()\n",
    "        stem = nn.Sequential(\n",
    "            nn.Conv3d(in_chans, dims[0], kernel_size=5, stride=3),\n",
    "            LayerNorm(dims[0], eps=1e-6, data_format=\"channels_first\")\n",
    "        )\n",
    "        self.downsample_layers.append(stem)\n",
    "        for i in range(3):\n",
    "            downsample_layer = nn.Sequential(\n",
    "                LayerNorm(dims[i], eps=1e-6, data_format=\"channels_first\"),\n",
    "                nn.Conv3d(dims[i], dims[i+1], kernel_size=2, stride=2),\n",
    "            )\n",
    "            self.downsample_layers.append(downsample_layer)\n",
    "\n",
    "        self.stages = nn.ModuleList()\n",
    "        dp_rates = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]\n",
    "        cur = 0\n",
    "        for i in range(4):\n",
    "            stage = nn.Sequential(\n",
    "                *[Block(dim=dims[i], drop_path=dp_rates[cur + j], \n",
    "                layer_scale_init_value=layer_scale_init_value) for j in range(depths[i])]\n",
    "            )\n",
    "            self.stages.append(stage)\n",
    "            cur += depths[i]\n",
    "\n",
    "        self.norm = nn.LayerNorm(dims[-1], eps=1e-6)  # final normalization\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(dims[-1], 4096),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "        self.head_cond = nn.Linear(4096, nc_cond)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "        self.head_cond.weight.data.mul_(head_init_scale)\n",
    "        self.head_cond.bias.data.mul_(head_init_scale)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, (nn.Conv3d, nn.Linear)):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        for i in range(4):\n",
    "            x = self.downsample_layers[i](x)\n",
    "            x = self.stages[i](x)\n",
    "        return self.norm(x.mean([-3, -2, -1]))  # global average pooling over spatial dimensions\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.fc_layers(x)\n",
    "        cond_output = self.head_cond(x)\n",
    "        return cond_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00428464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, criterion, optimizer, epoch):\n",
    "    print(f'Epoch {epoch + 1}, start')\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_log_loss = 0.0\n",
    "    batch_idx = 0\n",
    "    for img, cond, _ in train_loader:\n",
    "        batch_idx += 1\n",
    "        img = img.to(device)\n",
    "        cond = cond.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        cond_o = model(img)\n",
    "        loss_cond = criterion(cond_o, cond)\n",
    "        loss = loss_cond\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        running_log_loss += loss.item()\n",
    "        if (batch_idx + 1) % 1 == 0:\n",
    "            current_utc = datetime.datetime.utcnow()\n",
    "            gmt8_time = current_utc + datetime.timedelta(hours=8)\n",
    "            current_time = gmt8_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            with open('training_log.txt', 'a') as log_file:\n",
    "                log_entry = (f'Epoch {epoch+1:02}, Batch {batch_idx+1:04}: '\n",
    "                             f'Train Loss: {running_log_loss / 10:.4f}, '\n",
    "                             f'Timestamp: {current_time}\\n')\n",
    "                log_file.write(log_entry)\n",
    "            running_log_loss = 0\n",
    "    \n",
    "    return running_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1abdd197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, device, val_loader, criterion, epoch):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    cor_cond = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img, cond, _ in val_loader:\n",
    "            img = img.to(device)\n",
    "            cond = cond.to(device)\n",
    "            cond_o = model(img)\n",
    "            loss_cond = criterion(cond_o, cond)\n",
    "            loss = loss_cond\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            _, pred_cond = cond_o.max(1)\n",
    "            cor_cond += pred_cond.eq(cond).sum().item()\n",
    "            total += cond.size(0)\n",
    "            \n",
    "    val_loss = running_loss / len(val_loader)\n",
    "    acc_cond = 100. * cor_cond / total\n",
    "    \n",
    "    with open('validation_log.txt', 'a') as log_file:\n",
    "        current_utc = datetime.datetime.utcnow()\n",
    "        gmt8_time = current_utc + datetime.timedelta(hours=8)\n",
    "        current_time = gmt8_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        log_entry = (f'Epoch {epoch+1:03}, Val Loss: {val_loss:.4f}, '\n",
    "                     f'Val ACC cond: {acc_cond:.2f}%, Timestamp: {current_time}\\n')\n",
    "        log_file.write(log_entry)\n",
    "\n",
    "    return val_loss, acc_cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1c058e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model_name, path_prefix=\"\", epochs=10, lr=0.001, batch_size = 4):\n",
    "    # Configuration and Hyperparameters\n",
    "    batch_size = batch_size\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    train_set_file = f'train.txt'\n",
    "    val_set_file = f'test.txt'\n",
    "    \n",
    "    train_dataset = MRIDataset(train_set_file, path_prefix=path_prefix)\n",
    "    val_dataset = MRIDataset(val_set_file, path_prefix=path_prefix)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    nc_cond = len(train_dataset.cond_label)\n",
    "    grand_results = []\n",
    "    \n",
    "    with open('training_log.txt', 'w') as f:\n",
    "        f.write(\"\")  # This clears the training log\n",
    "    with open('validation_log.txt', 'w') as f:\n",
    "        f.write(\"\")  # This clears the validation log\n",
    "    \n",
    "    model = ConvNeXt(in_chans=1, nc_cond=nc_cond)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr)\n",
    "    \n",
    "    current_utc = datetime.datetime.utcnow()\n",
    "    gmt8_time = current_utc + datetime.timedelta(hours=8)\n",
    "    current_time = gmt8_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    start_time = f'Start training at: {current_time}'\n",
    "    print(start_time)\n",
    "        \n",
    "    # Training and Validation Loop\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train(model, device, train_loader, criterion, optimizer, epoch)\n",
    "        \n",
    "        val_loss, val_acc_cond = \\\n",
    "        validate(model, device, val_loader, criterion, epoch)\n",
    "        \n",
    "        current_utc = datetime.datetime.utcnow()\n",
    "        gmt8_time = current_utc + datetime.timedelta(hours=8)\n",
    "        current_time = gmt8_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        start_time = f'Start training at: {current_time}'\n",
    "        print(f'Epoch {epoch+1:03}, Train Loss: {train_loss:.4f}, Timestamp: {current_time},\\n'\n",
    "              f'Val Loss: {val_loss:.4f}, Val ACC cond: {val_acc_cond:.2f}%')\n",
    "        \n",
    "    torch.save(model.state_dict(), f'{model_name}_epoch10.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c436ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training at: 2024-06-12 13:26:15\n",
      "Epoch 1, start\n",
      "Epoch 001, Train Loss: 1.3375, Timestamp: 2024-06-12 13:26:27,\n",
      "Val Loss: 0.9920, Val ACC cond: 50.00%\n",
      "Epoch 2, start\n",
      "Epoch 002, Train Loss: 0.8128, Timestamp: 2024-06-12 13:26:39,\n",
      "Val Loss: 0.7909, Val ACC cond: 50.00%\n",
      "Epoch 3, start\n",
      "Epoch 003, Train Loss: 0.7228, Timestamp: 2024-06-12 13:26:51,\n",
      "Val Loss: 0.7034, Val ACC cond: 50.00%\n",
      "Epoch 4, start\n",
      "Epoch 004, Train Loss: 0.6866, Timestamp: 2024-06-12 13:27:03,\n",
      "Val Loss: 0.7099, Val ACC cond: 50.00%\n",
      "Epoch 5, start\n",
      "Epoch 005, Train Loss: 0.6722, Timestamp: 2024-06-12 13:27:15,\n",
      "Val Loss: 0.9807, Val ACC cond: 50.00%\n",
      "Epoch 6, start\n",
      "Epoch 006, Train Loss: 0.7711, Timestamp: 2024-06-12 13:27:27,\n",
      "Val Loss: 0.8694, Val ACC cond: 50.00%\n",
      "Epoch 7, start\n",
      "Epoch 007, Train Loss: 0.7348, Timestamp: 2024-06-12 13:27:39,\n",
      "Val Loss: 0.6918, Val ACC cond: 50.00%\n",
      "Epoch 8, start\n",
      "Epoch 008, Train Loss: 0.6754, Timestamp: 2024-06-12 13:27:52,\n",
      "Val Loss: 0.7002, Val ACC cond: 50.00%\n",
      "Epoch 9, start\n",
      "Epoch 009, Train Loss: 0.6657, Timestamp: 2024-06-12 13:28:05,\n",
      "Val Loss: 0.7178, Val ACC cond: 50.00%\n",
      "Epoch 10, start\n",
      "Epoch 010, Train Loss: 0.6434, Timestamp: 2024-06-12 13:28:17,\n",
      "Val Loss: 0.7161, Val ACC cond: 50.00%\n",
      "Start training at: 2024-06-12 13:28:18\n",
      "Epoch 1, start\n",
      "Epoch 001, Train Loss: 1.2649, Timestamp: 2024-06-12 13:28:30,\n",
      "Val Loss: 0.7297, Val ACC cond: 50.00%\n",
      "Epoch 2, start\n",
      "Epoch 002, Train Loss: 0.9301, Timestamp: 2024-06-12 13:28:42,\n",
      "Val Loss: 0.8518, Val ACC cond: 50.00%\n",
      "Epoch 3, start\n",
      "Epoch 003, Train Loss: 0.8341, Timestamp: 2024-06-12 13:28:54,\n",
      "Val Loss: 0.8523, Val ACC cond: 50.00%\n",
      "Epoch 4, start\n",
      "Epoch 004, Train Loss: 0.7950, Timestamp: 2024-06-12 13:29:05,\n",
      "Val Loss: 0.7160, Val ACC cond: 50.00%\n",
      "Epoch 5, start\n",
      "Epoch 005, Train Loss: 0.7386, Timestamp: 2024-06-12 13:29:17,\n",
      "Val Loss: 0.7440, Val ACC cond: 50.00%\n",
      "Epoch 6, start\n",
      "Epoch 006, Train Loss: 0.7541, Timestamp: 2024-06-12 13:29:28,\n",
      "Val Loss: 0.7446, Val ACC cond: 50.00%\n",
      "Epoch 7, start\n",
      "Epoch 007, Train Loss: 0.6826, Timestamp: 2024-06-12 13:29:39,\n",
      "Val Loss: 0.7523, Val ACC cond: 50.00%\n",
      "Epoch 8, start\n",
      "Epoch 008, Train Loss: 0.6977, Timestamp: 2024-06-12 13:29:51,\n",
      "Val Loss: 0.7817, Val ACC cond: 50.00%\n",
      "Epoch 9, start\n",
      "Epoch 009, Train Loss: 0.6751, Timestamp: 2024-06-12 13:30:03,\n",
      "Val Loss: 0.7589, Val ACC cond: 50.00%\n",
      "Epoch 10, start\n",
      "Epoch 010, Train Loss: 0.6429, Timestamp: 2024-06-12 13:30:14,\n",
      "Val Loss: 0.8249, Val ACC cond: 50.00%\n",
      "Start training at: 2024-06-12 13:30:15\n",
      "Epoch 1, start\n",
      "Epoch 001, Train Loss: 0.9931, Timestamp: 2024-06-12 13:30:27,\n",
      "Val Loss: 2.1273, Val ACC cond: 50.00%\n",
      "Epoch 2, start\n",
      "Epoch 002, Train Loss: 1.1585, Timestamp: 2024-06-12 13:30:39,\n",
      "Val Loss: 0.9252, Val ACC cond: 50.00%\n",
      "Epoch 3, start\n",
      "Epoch 003, Train Loss: 0.9005, Timestamp: 2024-06-12 13:30:51,\n",
      "Val Loss: 0.7606, Val ACC cond: 50.00%\n",
      "Epoch 4, start\n",
      "Epoch 004, Train Loss: 0.7293, Timestamp: 2024-06-12 13:31:03,\n",
      "Val Loss: 0.7031, Val ACC cond: 0.00%\n",
      "Epoch 5, start\n",
      "Epoch 005, Train Loss: 0.6908, Timestamp: 2024-06-12 13:31:15,\n",
      "Val Loss: 0.7130, Val ACC cond: 50.00%\n",
      "Epoch 6, start\n",
      "Epoch 006, Train Loss: 0.6928, Timestamp: 2024-06-12 13:31:27,\n",
      "Val Loss: 0.7224, Val ACC cond: 0.00%\n",
      "Epoch 7, start\n",
      "Epoch 007, Train Loss: 0.7133, Timestamp: 2024-06-12 13:31:39,\n",
      "Val Loss: 0.7881, Val ACC cond: 50.00%\n",
      "Epoch 8, start\n",
      "Epoch 008, Train Loss: 0.7362, Timestamp: 2024-06-12 13:31:51,\n",
      "Val Loss: 0.7454, Val ACC cond: 50.00%\n",
      "Epoch 9, start\n",
      "Epoch 009, Train Loss: 0.6868, Timestamp: 2024-06-12 13:32:03,\n",
      "Val Loss: 0.7401, Val ACC cond: 50.00%\n",
      "Epoch 10, start\n",
      "Epoch 010, Train Loss: 0.6491, Timestamp: 2024-06-12 13:32:15,\n",
      "Val Loss: 0.7592, Val ACC cond: 50.00%\n",
      "Start training at: 2024-06-12 13:32:16\n",
      "Epoch 1, start\n",
      "Epoch 001, Train Loss: 1.2693, Timestamp: 2024-06-12 13:32:28,\n",
      "Val Loss: 0.9049, Val ACC cond: 50.00%\n",
      "Epoch 2, start\n",
      "Epoch 002, Train Loss: 0.8412, Timestamp: 2024-06-12 13:32:40,\n",
      "Val Loss: 0.6925, Val ACC cond: 50.00%\n",
      "Epoch 3, start\n",
      "Epoch 003, Train Loss: 0.7296, Timestamp: 2024-06-12 13:32:52,\n",
      "Val Loss: 0.8794, Val ACC cond: 50.00%\n",
      "Epoch 4, start\n",
      "Epoch 004, Train Loss: 0.7034, Timestamp: 2024-06-12 13:33:04,\n",
      "Val Loss: 0.7637, Val ACC cond: 50.00%\n",
      "Epoch 5, start\n",
      "Epoch 005, Train Loss: 0.7279, Timestamp: 2024-06-12 13:33:16,\n",
      "Val Loss: 0.7485, Val ACC cond: 50.00%\n",
      "Epoch 6, start\n",
      "Epoch 006, Train Loss: 0.7385, Timestamp: 2024-06-12 13:33:29,\n",
      "Val Loss: 0.7469, Val ACC cond: 50.00%\n",
      "Epoch 7, start\n",
      "Epoch 007, Train Loss: 0.7085, Timestamp: 2024-06-12 13:33:41,\n",
      "Val Loss: 0.6934, Val ACC cond: 50.00%\n",
      "Epoch 8, start\n",
      "Epoch 008, Train Loss: 0.7049, Timestamp: 2024-06-12 13:33:53,\n",
      "Val Loss: 0.8179, Val ACC cond: 50.00%\n",
      "Epoch 9, start\n",
      "Epoch 009, Train Loss: 0.7503, Timestamp: 2024-06-12 13:34:05,\n",
      "Val Loss: 0.7001, Val ACC cond: 50.00%\n",
      "Epoch 10, start\n",
      "Epoch 010, Train Loss: 0.6987, Timestamp: 2024-06-12 13:34:17,\n",
      "Val Loss: 0.7204, Val ACC cond: 50.00%\n",
      "Start training at: 2024-06-12 13:34:18\n",
      "Epoch 1, start\n",
      "Epoch 001, Train Loss: 1.1728, Timestamp: 2024-06-12 13:34:30,\n",
      "Val Loss: 0.7252, Val ACC cond: 50.00%\n",
      "Epoch 2, start\n",
      "Epoch 002, Train Loss: 0.7222, Timestamp: 2024-06-12 13:34:42,\n",
      "Val Loss: 0.7551, Val ACC cond: 50.00%\n",
      "Epoch 3, start\n",
      "Epoch 003, Train Loss: 0.6960, Timestamp: 2024-06-12 13:34:55,\n",
      "Val Loss: 0.7556, Val ACC cond: 50.00%\n",
      "Epoch 4, start\n",
      "Epoch 004, Train Loss: 0.6811, Timestamp: 2024-06-12 13:35:08,\n",
      "Val Loss: 0.8543, Val ACC cond: 50.00%\n",
      "Epoch 5, start\n",
      "Epoch 005, Train Loss: 0.7398, Timestamp: 2024-06-12 13:35:21,\n",
      "Val Loss: 0.7130, Val ACC cond: 50.00%\n",
      "Epoch 6, start\n",
      "Epoch 006, Train Loss: 0.8025, Timestamp: 2024-06-12 13:35:33,\n",
      "Val Loss: 0.8991, Val ACC cond: 50.00%\n",
      "Epoch 7, start\n",
      "Epoch 007, Train Loss: 0.8075, Timestamp: 2024-06-12 13:35:45,\n",
      "Val Loss: 0.7459, Val ACC cond: 50.00%\n",
      "Epoch 8, start\n",
      "Epoch 008, Train Loss: 0.6729, Timestamp: 2024-06-12 13:35:57,\n",
      "Val Loss: 0.7355, Val ACC cond: 50.00%\n",
      "Epoch 9, start\n",
      "Epoch 009, Train Loss: 0.6628, Timestamp: 2024-06-12 13:36:09,\n",
      "Val Loss: 0.7260, Val ACC cond: 50.00%\n",
      "Epoch 10, start\n",
      "Epoch 010, Train Loss: 0.6261, Timestamp: 2024-06-12 13:36:21,\n",
      "Val Loss: 0.7564, Val ACC cond: 50.00%\n",
      "Start training at: 2024-06-12 13:36:22\n",
      "Epoch 1, start\n",
      "Epoch 001, Train Loss: 1.2654, Timestamp: 2024-06-12 13:36:33,\n",
      "Val Loss: 0.8897, Val ACC cond: 50.00%\n",
      "Epoch 2, start\n",
      "Epoch 002, Train Loss: 0.7845, Timestamp: 2024-06-12 13:36:45,\n",
      "Val Loss: 0.9587, Val ACC cond: 50.00%\n",
      "Epoch 3, start\n",
      "Epoch 003, Train Loss: 0.8781, Timestamp: 2024-06-12 13:36:57,\n",
      "Val Loss: 0.7297, Val ACC cond: 50.00%\n",
      "Epoch 4, start\n",
      "Epoch 004, Train Loss: 0.6980, Timestamp: 2024-06-12 13:37:10,\n",
      "Val Loss: 0.6991, Val ACC cond: 50.00%\n",
      "Epoch 5, start\n",
      "Epoch 005, Train Loss: 0.6842, Timestamp: 2024-06-12 13:37:22,\n",
      "Val Loss: 0.7674, Val ACC cond: 50.00%\n",
      "Epoch 6, start\n",
      "Epoch 006, Train Loss: 0.6828, Timestamp: 2024-06-12 13:37:34,\n",
      "Val Loss: 0.7157, Val ACC cond: 0.00%\n",
      "Epoch 7, start\n",
      "Epoch 007, Train Loss: 0.6650, Timestamp: 2024-06-12 13:37:46,\n",
      "Val Loss: 0.7177, Val ACC cond: 0.00%\n",
      "Epoch 8, start\n",
      "Epoch 008, Train Loss: 0.6499, Timestamp: 2024-06-12 13:37:59,\n",
      "Val Loss: 0.7258, Val ACC cond: 50.00%\n",
      "Epoch 9, start\n",
      "Epoch 009, Train Loss: 0.7271, Timestamp: 2024-06-12 13:38:11,\n",
      "Val Loss: 0.8348, Val ACC cond: 50.00%\n",
      "Epoch 10, start\n",
      "Epoch 010, Train Loss: 0.6315, Timestamp: 2024-06-12 13:38:23,\n",
      "Val Loss: 0.7312, Val ACC cond: 50.00%\n",
      "Start training at: 2024-06-12 13:38:24\n",
      "Epoch 1, start\n",
      "Epoch 001, Train Loss: 1.1899, Timestamp: 2024-06-12 13:38:36,\n",
      "Val Loss: 0.8037, Val ACC cond: 0.00%\n",
      "Epoch 2, start\n",
      "Epoch 002, Train Loss: 0.7832, Timestamp: 2024-06-12 13:38:48,\n",
      "Val Loss: 0.8907, Val ACC cond: 50.00%\n",
      "Epoch 3, start\n",
      "Epoch 003, Train Loss: 1.0168, Timestamp: 2024-06-12 13:39:00,\n",
      "Val Loss: 0.8129, Val ACC cond: 50.00%\n",
      "Epoch 4, start\n",
      "Epoch 004, Train Loss: 0.7997, Timestamp: 2024-06-12 13:39:12,\n",
      "Val Loss: 0.7340, Val ACC cond: 50.00%\n",
      "Epoch 5, start\n",
      "Epoch 005, Train Loss: 0.7036, Timestamp: 2024-06-12 13:39:24,\n",
      "Val Loss: 0.6918, Val ACC cond: 50.00%\n",
      "Epoch 6, start\n",
      "Epoch 006, Train Loss: 0.7374, Timestamp: 2024-06-12 13:39:36,\n",
      "Val Loss: 0.6601, Val ACC cond: 50.00%\n",
      "Epoch 7, start\n",
      "Epoch 007, Train Loss: 0.6968, Timestamp: 2024-06-12 13:39:48,\n",
      "Val Loss: 0.6734, Val ACC cond: 50.00%\n",
      "Epoch 8, start\n",
      "Epoch 008, Train Loss: 0.6876, Timestamp: 2024-06-12 13:40:00,\n",
      "Val Loss: 0.6356, Val ACC cond: 100.00%\n",
      "Epoch 9, start\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009, Train Loss: 0.6569, Timestamp: 2024-06-12 13:40:12,\n",
      "Val Loss: 0.6354, Val ACC cond: 50.00%\n",
      "Epoch 10, start\n",
      "Epoch 010, Train Loss: 0.6423, Timestamp: 2024-06-12 13:40:25,\n",
      "Val Loss: 0.6234, Val ACC cond: 50.00%\n",
      "Start training at: 2024-06-12 13:40:26\n",
      "Epoch 1, start\n",
      "Epoch 001, Train Loss: 1.2351, Timestamp: 2024-06-12 13:40:37,\n",
      "Val Loss: 0.7252, Val ACC cond: 50.00%\n",
      "Epoch 2, start\n",
      "Epoch 002, Train Loss: 0.9800, Timestamp: 2024-06-12 13:40:49,\n",
      "Val Loss: 0.7931, Val ACC cond: 50.00%\n",
      "Epoch 3, start\n",
      "Epoch 003, Train Loss: 0.7805, Timestamp: 2024-06-12 13:41:02,\n",
      "Val Loss: 0.8520, Val ACC cond: 0.00%\n",
      "Epoch 4, start\n",
      "Epoch 004, Train Loss: 0.7714, Timestamp: 2024-06-12 13:41:14,\n",
      "Val Loss: 0.7208, Val ACC cond: 50.00%\n",
      "Epoch 5, start\n",
      "Epoch 005, Train Loss: 0.7191, Timestamp: 2024-06-12 13:41:26,\n",
      "Val Loss: 0.6981, Val ACC cond: 50.00%\n",
      "Epoch 6, start\n",
      "Epoch 006, Train Loss: 0.6922, Timestamp: 2024-06-12 13:41:39,\n",
      "Val Loss: 0.6992, Val ACC cond: 50.00%\n",
      "Epoch 7, start\n",
      "Epoch 007, Train Loss: 0.6763, Timestamp: 2024-06-12 13:41:53,\n",
      "Val Loss: 0.7422, Val ACC cond: 50.00%\n",
      "Epoch 8, start\n",
      "Epoch 008, Train Loss: 0.6910, Timestamp: 2024-06-12 13:42:06,\n",
      "Val Loss: 0.7272, Val ACC cond: 50.00%\n",
      "Epoch 9, start\n",
      "Epoch 009, Train Loss: 0.6682, Timestamp: 2024-06-12 13:42:18,\n",
      "Val Loss: 0.7028, Val ACC cond: 50.00%\n",
      "Epoch 10, start\n",
      "Epoch 010, Train Loss: 0.7044, Timestamp: 2024-06-12 13:42:30,\n",
      "Val Loss: 0.6867, Val ACC cond: 50.00%\n",
      "Start training at: 2024-06-12 13:42:31\n",
      "Epoch 1, start\n",
      "Epoch 001, Train Loss: 1.3397, Timestamp: 2024-06-12 13:42:43,\n",
      "Val Loss: 1.5728, Val ACC cond: 50.00%\n",
      "Epoch 2, start\n",
      "Epoch 002, Train Loss: 1.0442, Timestamp: 2024-06-12 13:42:55,\n",
      "Val Loss: 0.7156, Val ACC cond: 50.00%\n",
      "Epoch 3, start\n",
      "Epoch 003, Train Loss: 0.8715, Timestamp: 2024-06-12 13:43:08,\n",
      "Val Loss: 0.7373, Val ACC cond: 50.00%\n",
      "Epoch 4, start\n",
      "Epoch 004, Train Loss: 0.7422, Timestamp: 2024-06-12 13:43:20,\n",
      "Val Loss: 0.6912, Val ACC cond: 50.00%\n",
      "Epoch 5, start\n",
      "Epoch 005, Train Loss: 0.6778, Timestamp: 2024-06-12 13:43:32,\n",
      "Val Loss: 0.6966, Val ACC cond: 50.00%\n",
      "Epoch 6, start\n",
      "Epoch 006, Train Loss: 0.6849, Timestamp: 2024-06-12 13:43:45,\n",
      "Val Loss: 0.6918, Val ACC cond: 50.00%\n",
      "Epoch 7, start\n",
      "Epoch 007, Train Loss: 0.6666, Timestamp: 2024-06-12 13:43:57,\n",
      "Val Loss: 0.7096, Val ACC cond: 50.00%\n",
      "Epoch 8, start\n",
      "Epoch 008, Train Loss: 0.6608, Timestamp: 2024-06-12 13:44:09,\n",
      "Val Loss: 0.7352, Val ACC cond: 50.00%\n",
      "Epoch 9, start\n",
      "Epoch 009, Train Loss: 0.6591, Timestamp: 2024-06-12 13:44:22,\n",
      "Val Loss: 0.6909, Val ACC cond: 50.00%\n",
      "Epoch 10, start\n",
      "Epoch 010, Train Loss: 0.6581, Timestamp: 2024-06-12 13:44:35,\n",
      "Val Loss: 0.6839, Val ACC cond: 50.00%\n",
      "Start training at: 2024-06-12 13:44:36\n",
      "Epoch 1, start\n",
      "Epoch 001, Train Loss: 1.0782, Timestamp: 2024-06-12 13:44:48,\n",
      "Val Loss: 0.9324, Val ACC cond: 50.00%\n",
      "Epoch 2, start\n",
      "Epoch 002, Train Loss: 0.8819, Timestamp: 2024-06-12 13:45:00,\n",
      "Val Loss: 0.6967, Val ACC cond: 50.00%\n",
      "Epoch 3, start\n",
      "Epoch 003, Train Loss: 0.7285, Timestamp: 2024-06-12 13:45:13,\n",
      "Val Loss: 0.6535, Val ACC cond: 50.00%\n",
      "Epoch 4, start\n",
      "Epoch 004, Train Loss: 0.7394, Timestamp: 2024-06-12 13:45:25,\n",
      "Val Loss: 0.6734, Val ACC cond: 50.00%\n",
      "Epoch 5, start\n",
      "Epoch 005, Train Loss: 0.7667, Timestamp: 2024-06-12 13:45:37,\n",
      "Val Loss: 0.7998, Val ACC cond: 50.00%\n",
      "Epoch 6, start\n",
      "Epoch 006, Train Loss: 0.8020, Timestamp: 2024-06-12 13:45:49,\n",
      "Val Loss: 0.7303, Val ACC cond: 50.00%\n",
      "Epoch 7, start\n",
      "Epoch 007, Train Loss: 0.7154, Timestamp: 2024-06-12 13:46:02,\n",
      "Val Loss: 0.6676, Val ACC cond: 50.00%\n",
      "Epoch 8, start\n",
      "Epoch 008, Train Loss: 0.6780, Timestamp: 2024-06-12 13:46:14,\n",
      "Val Loss: 0.6480, Val ACC cond: 100.00%\n",
      "Epoch 9, start\n",
      "Epoch 009, Train Loss: 0.6621, Timestamp: 2024-06-12 13:46:26,\n",
      "Val Loss: 0.6505, Val ACC cond: 50.00%\n",
      "Epoch 10, start\n",
      "Epoch 010, Train Loss: 0.6527, Timestamp: 2024-06-12 13:46:38,\n",
      "Val Loss: 0.6366, Val ACC cond: 50.00%\n",
      "Start training at: 2024-06-12 13:46:39\n",
      "Epoch 1, start\n",
      "Epoch 001, Train Loss: 1.3131, Timestamp: 2024-06-12 13:46:51,\n",
      "Val Loss: 0.8105, Val ACC cond: 50.00%\n",
      "Epoch 2, start\n",
      "Epoch 002, Train Loss: 0.9470, Timestamp: 2024-06-12 13:47:03,\n",
      "Val Loss: 0.7915, Val ACC cond: 50.00%\n",
      "Epoch 3, start\n",
      "Epoch 003, Train Loss: 0.7343, Timestamp: 2024-06-12 13:47:14,\n",
      "Val Loss: 0.7021, Val ACC cond: 50.00%\n",
      "Epoch 4, start\n",
      "Epoch 004, Train Loss: 0.7025, Timestamp: 2024-06-12 13:47:26,\n",
      "Val Loss: 0.6882, Val ACC cond: 50.00%\n",
      "Epoch 5, start\n",
      "Epoch 005, Train Loss: 0.6838, Timestamp: 2024-06-12 13:47:38,\n",
      "Val Loss: 0.6893, Val ACC cond: 50.00%\n",
      "Epoch 6, start\n",
      "Epoch 006, Train Loss: 0.6900, Timestamp: 2024-06-12 13:47:50,\n",
      "Val Loss: 0.6732, Val ACC cond: 100.00%\n",
      "Epoch 7, start\n",
      "Epoch 007, Train Loss: 0.6815, Timestamp: 2024-06-12 13:48:02,\n",
      "Val Loss: 0.7008, Val ACC cond: 50.00%\n",
      "Epoch 8, start\n",
      "Epoch 008, Train Loss: 0.6912, Timestamp: 2024-06-12 13:48:14,\n",
      "Val Loss: 0.6652, Val ACC cond: 100.00%\n",
      "Epoch 9, start\n",
      "Epoch 009, Train Loss: 0.7362, Timestamp: 2024-06-12 13:48:25,\n",
      "Val Loss: 0.7662, Val ACC cond: 50.00%\n",
      "Epoch 10, start\n",
      "Epoch 010, Train Loss: 0.7070, Timestamp: 2024-06-12 13:48:37,\n",
      "Val Loss: 0.6675, Val ACC cond: 50.00%\n",
      "Start training at: 2024-06-12 13:48:38\n",
      "Epoch 1, start\n",
      "Epoch 001, Train Loss: 1.6555, Timestamp: 2024-06-12 13:48:50,\n",
      "Val Loss: 0.7106, Val ACC cond: 50.00%\n",
      "Epoch 2, start\n",
      "Epoch 002, Train Loss: 0.7379, Timestamp: 2024-06-12 13:49:02,\n",
      "Val Loss: 0.8407, Val ACC cond: 50.00%\n",
      "Epoch 3, start\n",
      "Epoch 003, Train Loss: 0.7623, Timestamp: 2024-06-12 13:49:14,\n",
      "Val Loss: 0.7080, Val ACC cond: 50.00%\n",
      "Epoch 4, start\n",
      "Epoch 004, Train Loss: 0.6770, Timestamp: 2024-06-12 13:49:27,\n",
      "Val Loss: 0.7736, Val ACC cond: 50.00%\n",
      "Epoch 5, start\n",
      "Epoch 005, Train Loss: 0.6912, Timestamp: 2024-06-12 13:49:39,\n",
      "Val Loss: 0.7381, Val ACC cond: 50.00%\n",
      "Epoch 6, start\n",
      "Epoch 006, Train Loss: 0.7084, Timestamp: 2024-06-12 13:49:51,\n",
      "Val Loss: 0.7267, Val ACC cond: 50.00%\n",
      "Epoch 7, start\n",
      "Epoch 007, Train Loss: 0.6874, Timestamp: 2024-06-12 13:50:03,\n",
      "Val Loss: 0.6797, Val ACC cond: 50.00%\n",
      "Epoch 8, start\n",
      "Epoch 008, Train Loss: 0.6596, Timestamp: 2024-06-12 13:50:15,\n",
      "Val Loss: 0.9250, Val ACC cond: 50.00%\n",
      "Epoch 9, start\n",
      "Epoch 009, Train Loss: 0.8152, Timestamp: 2024-06-12 13:50:28,\n",
      "Val Loss: 0.7104, Val ACC cond: 50.00%\n",
      "Epoch 10, start\n",
      "Epoch 010, Train Loss: 0.6782, Timestamp: 2024-06-12 13:50:40,\n",
      "Val Loss: 0.7215, Val ACC cond: 50.00%\n",
      "Start training at: 2024-06-12 13:50:41\n",
      "Epoch 1, start\n",
      "Epoch 001, Train Loss: 1.2350, Timestamp: 2024-06-12 13:50:53,\n",
      "Val Loss: 0.9589, Val ACC cond: 50.00%\n",
      "Epoch 2, start\n",
      "Epoch 002, Train Loss: 0.9779, Timestamp: 2024-06-12 13:51:06,\n",
      "Val Loss: 0.6996, Val ACC cond: 50.00%\n",
      "Epoch 3, start\n",
      "Epoch 003, Train Loss: 0.7449, Timestamp: 2024-06-12 13:51:18,\n",
      "Val Loss: 0.8531, Val ACC cond: 50.00%\n",
      "Epoch 4, start\n",
      "Epoch 004, Train Loss: 0.7017, Timestamp: 2024-06-12 13:51:30,\n",
      "Val Loss: 0.7517, Val ACC cond: 50.00%\n",
      "Epoch 5, start\n",
      "Epoch 005, Train Loss: 0.6567, Timestamp: 2024-06-12 13:51:42,\n",
      "Val Loss: 0.7498, Val ACC cond: 50.00%\n",
      "Epoch 6, start\n",
      "Epoch 006, Train Loss: 0.7057, Timestamp: 2024-06-12 13:51:53,\n",
      "Val Loss: 0.7206, Val ACC cond: 50.00%\n",
      "Epoch 7, start\n",
      "Epoch 007, Train Loss: 0.6698, Timestamp: 2024-06-12 13:52:05,\n",
      "Val Loss: 0.8566, Val ACC cond: 50.00%\n",
      "Epoch 8, start\n",
      "Epoch 008, Train Loss: 0.6395, Timestamp: 2024-06-12 13:52:16,\n",
      "Val Loss: 0.6808, Val ACC cond: 50.00%\n",
      "Epoch 9, start\n",
      "Epoch 009, Train Loss: 0.6060, Timestamp: 2024-06-12 13:52:28,\n",
      "Val Loss: 0.6952, Val ACC cond: 50.00%\n",
      "Epoch 10, start\n",
      "Epoch 010, Train Loss: 0.6430, Timestamp: 2024-06-12 13:52:39,\n",
      "Val Loss: 0.7010, Val ACC cond: 50.00%\n",
      "Start training at: 2024-06-12 13:52:40\n",
      "Epoch 1, start\n",
      "Epoch 001, Train Loss: 1.1783, Timestamp: 2024-06-12 13:52:52,\n",
      "Val Loss: 0.9857, Val ACC cond: 50.00%\n",
      "Epoch 2, start\n",
      "Epoch 002, Train Loss: 0.8092, Timestamp: 2024-06-12 13:53:03,\n",
      "Val Loss: 0.6862, Val ACC cond: 50.00%\n",
      "Epoch 3, start\n",
      "Epoch 003, Train Loss: 0.7830, Timestamp: 2024-06-12 13:53:14,\n",
      "Val Loss: 0.9340, Val ACC cond: 50.00%\n",
      "Epoch 4, start\n",
      "Epoch 004, Train Loss: 0.7437, Timestamp: 2024-06-12 13:53:26,\n",
      "Val Loss: 0.6723, Val ACC cond: 50.00%\n",
      "Epoch 5, start\n",
      "Epoch 005, Train Loss: 0.6983, Timestamp: 2024-06-12 13:53:37,\n",
      "Val Loss: 0.6867, Val ACC cond: 50.00%\n",
      "Epoch 6, start\n",
      "Epoch 006, Train Loss: 0.6699, Timestamp: 2024-06-12 13:53:49,\n",
      "Val Loss: 0.6822, Val ACC cond: 50.00%\n",
      "Epoch 7, start\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007, Train Loss: 0.6756, Timestamp: 2024-06-12 13:54:00,\n",
      "Val Loss: 0.6842, Val ACC cond: 50.00%\n",
      "Epoch 8, start\n",
      "Epoch 008, Train Loss: 0.6319, Timestamp: 2024-06-12 13:54:11,\n",
      "Val Loss: 0.6708, Val ACC cond: 50.00%\n",
      "Epoch 9, start\n",
      "Epoch 009, Train Loss: 0.6175, Timestamp: 2024-06-12 13:54:23,\n",
      "Val Loss: 0.6920, Val ACC cond: 50.00%\n",
      "Epoch 10, start\n",
      "Epoch 010, Train Loss: 0.5624, Timestamp: 2024-06-12 13:54:34,\n",
      "Val Loss: 0.6378, Val ACC cond: 100.00%\n",
      "Start training at: 2024-06-12 13:54:35\n",
      "Epoch 1, start\n",
      "Epoch 001, Train Loss: 1.1746, Timestamp: 2024-06-12 13:54:46,\n",
      "Val Loss: 1.3972, Val ACC cond: 50.00%\n",
      "Epoch 2, start\n",
      "Epoch 002, Train Loss: 0.9391, Timestamp: 2024-06-12 13:54:58,\n",
      "Val Loss: 0.7131, Val ACC cond: 50.00%\n",
      "Epoch 3, start\n",
      "Epoch 003, Train Loss: 0.7708, Timestamp: 2024-06-12 13:55:09,\n",
      "Val Loss: 0.7853, Val ACC cond: 50.00%\n",
      "Epoch 4, start\n",
      "Epoch 004, Train Loss: 0.7450, Timestamp: 2024-06-12 13:55:21,\n",
      "Val Loss: 0.6873, Val ACC cond: 50.00%\n",
      "Epoch 5, start\n",
      "Epoch 005, Train Loss: 0.7191, Timestamp: 2024-06-12 13:55:32,\n",
      "Val Loss: 0.6800, Val ACC cond: 50.00%\n",
      "Epoch 6, start\n",
      "Epoch 006, Train Loss: 0.7227, Timestamp: 2024-06-12 13:55:44,\n",
      "Val Loss: 0.7358, Val ACC cond: 50.00%\n",
      "Epoch 7, start\n",
      "Epoch 007, Train Loss: 0.7245, Timestamp: 2024-06-12 13:55:56,\n",
      "Val Loss: 0.6837, Val ACC cond: 50.00%\n",
      "Epoch 8, start\n",
      "Epoch 008, Train Loss: 0.7086, Timestamp: 2024-06-12 13:56:08,\n",
      "Val Loss: 0.6722, Val ACC cond: 50.00%\n",
      "Epoch 9, start\n",
      "Epoch 009, Train Loss: 0.6926, Timestamp: 2024-06-12 13:56:20,\n",
      "Val Loss: 0.7020, Val ACC cond: 50.00%\n",
      "Epoch 10, start\n",
      "Epoch 010, Train Loss: 0.6696, Timestamp: 2024-06-12 13:56:31,\n",
      "Val Loss: 0.7040, Val ACC cond: 50.00%\n",
      "Start training at: 2024-06-12 13:56:32\n",
      "Epoch 1, start\n",
      "Epoch 001, Train Loss: 1.0531, Timestamp: 2024-06-12 13:56:44,\n",
      "Val Loss: 0.8892, Val ACC cond: 50.00%\n",
      "Epoch 2, start\n",
      "Epoch 002, Train Loss: 0.9023, Timestamp: 2024-06-12 13:56:56,\n",
      "Val Loss: 0.7497, Val ACC cond: 50.00%\n",
      "Epoch 3, start\n",
      "Epoch 003, Train Loss: 0.7168, Timestamp: 2024-06-12 13:57:07,\n",
      "Val Loss: 0.8190, Val ACC cond: 50.00%\n",
      "Epoch 4, start\n",
      "Epoch 004, Train Loss: 0.6773, Timestamp: 2024-06-12 13:57:19,\n",
      "Val Loss: 0.7184, Val ACC cond: 0.00%\n",
      "Epoch 5, start\n",
      "Epoch 005, Train Loss: 0.6696, Timestamp: 2024-06-12 13:57:31,\n",
      "Val Loss: 0.7938, Val ACC cond: 50.00%\n",
      "Epoch 6, start\n",
      "Epoch 006, Train Loss: 0.6930, Timestamp: 2024-06-12 13:57:46,\n",
      "Val Loss: 0.7402, Val ACC cond: 50.00%\n",
      "Epoch 7, start\n",
      "Epoch 007, Train Loss: 0.6498, Timestamp: 2024-06-12 13:58:02,\n",
      "Val Loss: 0.7599, Val ACC cond: 50.00%\n",
      "Epoch 8, start\n",
      "Epoch 008, Train Loss: 0.6144, Timestamp: 2024-06-12 13:58:18,\n",
      "Val Loss: 0.7690, Val ACC cond: 50.00%\n",
      "Epoch 9, start\n",
      "Epoch 009, Train Loss: 0.5668, Timestamp: 2024-06-12 13:58:31,\n",
      "Val Loss: 0.7125, Val ACC cond: 50.00%\n",
      "Epoch 10, start\n",
      "Epoch 010, Train Loss: 0.6040, Timestamp: 2024-06-12 13:58:44,\n",
      "Val Loss: 0.7356, Val ACC cond: 50.00%\n",
      "Start training at: 2024-06-12 13:58:45\n",
      "Epoch 1, start\n",
      "Epoch 001, Train Loss: 1.0217, Timestamp: 2024-06-12 13:58:57,\n",
      "Val Loss: 0.9267, Val ACC cond: 50.00%\n",
      "Epoch 2, start\n",
      "Epoch 002, Train Loss: 0.9831, Timestamp: 2024-06-12 13:59:09,\n",
      "Val Loss: 1.0647, Val ACC cond: 50.00%\n",
      "Epoch 3, start\n",
      "Epoch 003, Train Loss: 0.8148, Timestamp: 2024-06-12 13:59:21,\n",
      "Val Loss: 0.8051, Val ACC cond: 50.00%\n",
      "Epoch 4, start\n",
      "Epoch 004, Train Loss: 0.7241, Timestamp: 2024-06-12 13:59:33,\n",
      "Val Loss: 0.6494, Val ACC cond: 50.00%\n",
      "Epoch 5, start\n",
      "Epoch 005, Train Loss: 0.6919, Timestamp: 2024-06-12 13:59:46,\n",
      "Val Loss: 0.6406, Val ACC cond: 100.00%\n",
      "Epoch 6, start\n",
      "Epoch 006, Train Loss: 0.6624, Timestamp: 2024-06-12 13:59:58,\n",
      "Val Loss: 0.6488, Val ACC cond: 100.00%\n",
      "Epoch 7, start\n",
      "Epoch 007, Train Loss: 0.6711, Timestamp: 2024-06-12 14:00:10,\n",
      "Val Loss: 0.6542, Val ACC cond: 50.00%\n",
      "Epoch 8, start\n",
      "Epoch 008, Train Loss: 0.6567, Timestamp: 2024-06-12 14:00:22,\n",
      "Val Loss: 0.7436, Val ACC cond: 50.00%\n",
      "Epoch 9, start\n",
      "Epoch 009, Train Loss: 0.7096, Timestamp: 2024-06-12 14:00:35,\n",
      "Val Loss: 0.9073, Val ACC cond: 50.00%\n",
      "Epoch 10, start\n",
      "Epoch 010, Train Loss: 0.7445, Timestamp: 2024-06-12 14:00:47,\n",
      "Val Loss: 0.7472, Val ACC cond: 50.00%\n",
      "Start training at: 2024-06-12 14:00:48\n",
      "Epoch 1, start\n",
      "Epoch 001, Train Loss: 1.3416, Timestamp: 2024-06-12 14:01:01,\n",
      "Val Loss: 0.7581, Val ACC cond: 50.00%\n",
      "Epoch 2, start\n",
      "Epoch 002, Train Loss: 0.8280, Timestamp: 2024-06-12 14:01:15,\n",
      "Val Loss: 0.7634, Val ACC cond: 50.00%\n",
      "Epoch 3, start\n",
      "Epoch 003, Train Loss: 0.8611, Timestamp: 2024-06-12 14:01:29,\n",
      "Val Loss: 0.7595, Val ACC cond: 50.00%\n",
      "Epoch 4, start\n",
      "Epoch 004, Train Loss: 0.8309, Timestamp: 2024-06-12 14:01:41,\n",
      "Val Loss: 0.7571, Val ACC cond: 50.00%\n",
      "Epoch 5, start\n",
      "Epoch 005, Train Loss: 0.7263, Timestamp: 2024-06-12 14:01:53,\n",
      "Val Loss: 0.8088, Val ACC cond: 50.00%\n",
      "Epoch 6, start\n",
      "Epoch 006, Train Loss: 0.7358, Timestamp: 2024-06-12 14:02:06,\n",
      "Val Loss: 0.8422, Val ACC cond: 50.00%\n",
      "Epoch 7, start\n",
      "Epoch 007, Train Loss: 0.7689, Timestamp: 2024-06-12 14:02:19,\n",
      "Val Loss: 0.6917, Val ACC cond: 50.00%\n",
      "Epoch 8, start\n",
      "Epoch 008, Train Loss: 0.7595, Timestamp: 2024-06-12 14:02:32,\n",
      "Val Loss: 0.7690, Val ACC cond: 50.00%\n",
      "Epoch 9, start\n",
      "Epoch 009, Train Loss: 0.7139, Timestamp: 2024-06-12 14:02:44,\n",
      "Val Loss: 0.6949, Val ACC cond: 50.00%\n",
      "Epoch 10, start\n",
      "Epoch 010, Train Loss: 0.6572, Timestamp: 2024-06-12 14:02:57,\n",
      "Val Loss: 0.6599, Val ACC cond: 50.00%\n",
      "Start training at: 2024-06-12 14:02:58\n",
      "Epoch 1, start\n",
      "Epoch 001, Train Loss: 1.5770, Timestamp: 2024-06-12 14:03:11,\n",
      "Val Loss: 0.5770, Val ACC cond: 50.00%\n",
      "Epoch 2, start\n",
      "Epoch 002, Train Loss: 1.0515, Timestamp: 2024-06-12 14:03:24,\n",
      "Val Loss: 1.2817, Val ACC cond: 50.00%\n",
      "Epoch 3, start\n",
      "Epoch 003, Train Loss: 0.9296, Timestamp: 2024-06-12 14:03:37,\n",
      "Val Loss: 0.6502, Val ACC cond: 50.00%\n",
      "Epoch 4, start\n",
      "Epoch 004, Train Loss: 0.7262, Timestamp: 2024-06-12 14:03:50,\n",
      "Val Loss: 0.6449, Val ACC cond: 100.00%\n",
      "Epoch 5, start\n",
      "Epoch 005, Train Loss: 0.7136, Timestamp: 2024-06-12 14:04:03,\n",
      "Val Loss: 0.6679, Val ACC cond: 50.00%\n",
      "Epoch 6, start\n",
      "Epoch 006, Train Loss: 0.7093, Timestamp: 2024-06-12 14:04:15,\n",
      "Val Loss: 0.7217, Val ACC cond: 50.00%\n",
      "Epoch 7, start\n",
      "Epoch 007, Train Loss: 0.7408, Timestamp: 2024-06-12 14:04:28,\n",
      "Val Loss: 0.6567, Val ACC cond: 100.00%\n",
      "Epoch 8, start\n",
      "Epoch 008, Train Loss: 0.6756, Timestamp: 2024-06-12 14:04:42,\n",
      "Val Loss: 0.6675, Val ACC cond: 50.00%\n",
      "Epoch 9, start\n",
      "Epoch 009, Train Loss: 0.6697, Timestamp: 2024-06-12 14:04:54,\n",
      "Val Loss: 0.6542, Val ACC cond: 100.00%\n",
      "Epoch 10, start\n",
      "Epoch 010, Train Loss: 0.6742, Timestamp: 2024-06-12 14:05:06,\n",
      "Val Loss: 0.6421, Val ACC cond: 100.00%\n",
      "Start training at: 2024-06-12 14:05:07\n",
      "Epoch 1, start\n",
      "Epoch 001, Train Loss: 1.2736, Timestamp: 2024-06-12 14:05:20,\n",
      "Val Loss: 1.2756, Val ACC cond: 50.00%\n",
      "Epoch 2, start\n",
      "Epoch 002, Train Loss: 0.8984, Timestamp: 2024-06-12 14:05:33,\n",
      "Val Loss: 0.7854, Val ACC cond: 50.00%\n",
      "Epoch 3, start\n",
      "Epoch 003, Train Loss: 0.8102, Timestamp: 2024-06-12 14:05:45,\n",
      "Val Loss: 0.6865, Val ACC cond: 50.00%\n",
      "Epoch 4, start\n",
      "Epoch 004, Train Loss: 0.7389, Timestamp: 2024-06-12 14:05:57,\n",
      "Val Loss: 0.6554, Val ACC cond: 50.00%\n",
      "Epoch 5, start\n",
      "Epoch 005, Train Loss: 0.7082, Timestamp: 2024-06-12 14:06:09,\n",
      "Val Loss: 0.6163, Val ACC cond: 50.00%\n",
      "Epoch 6, start\n",
      "Epoch 006, Train Loss: 0.6638, Timestamp: 2024-06-12 14:06:22,\n",
      "Val Loss: 0.6282, Val ACC cond: 50.00%\n",
      "Epoch 7, start\n",
      "Epoch 007, Train Loss: 0.6571, Timestamp: 2024-06-12 14:06:34,\n",
      "Val Loss: 0.5856, Val ACC cond: 100.00%\n",
      "Epoch 8, start\n",
      "Epoch 008, Train Loss: 0.6426, Timestamp: 2024-06-12 14:06:47,\n",
      "Val Loss: 0.7646, Val ACC cond: 50.00%\n",
      "Epoch 9, start\n",
      "Epoch 009, Train Loss: 0.6927, Timestamp: 2024-06-12 14:06:59,\n",
      "Val Loss: 0.7674, Val ACC cond: 50.00%\n",
      "Epoch 10, start\n",
      "Epoch 010, Train Loss: 0.6508, Timestamp: 2024-06-12 14:07:11,\n",
      "Val Loss: 0.6650, Val ACC cond: 50.00%\n",
      "Start training at: 2024-06-12 14:07:12\n",
      "Epoch 1, start\n",
      "Epoch 001, Train Loss: 1.3990, Timestamp: 2024-06-12 14:07:25,\n",
      "Val Loss: 0.6837, Val ACC cond: 50.00%\n",
      "Epoch 2, start\n",
      "Epoch 002, Train Loss: 0.8858, Timestamp: 2024-06-12 14:07:38,\n",
      "Val Loss: 0.7254, Val ACC cond: 50.00%\n",
      "Epoch 3, start\n",
      "Epoch 003, Train Loss: 0.7317, Timestamp: 2024-06-12 14:07:50,\n",
      "Val Loss: 0.7040, Val ACC cond: 50.00%\n",
      "Epoch 4, start\n",
      "Epoch 004, Train Loss: 0.6938, Timestamp: 2024-06-12 14:08:03,\n",
      "Val Loss: 0.6975, Val ACC cond: 50.00%\n",
      "Epoch 5, start\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005, Train Loss: 0.7198, Timestamp: 2024-06-12 14:08:16,\n",
      "Val Loss: 0.7542, Val ACC cond: 50.00%\n",
      "Epoch 6, start\n",
      "Epoch 006, Train Loss: 0.6849, Timestamp: 2024-06-12 14:08:28,\n",
      "Val Loss: 0.7789, Val ACC cond: 50.00%\n",
      "Epoch 7, start\n",
      "Epoch 007, Train Loss: 0.7839, Timestamp: 2024-06-12 14:08:41,\n",
      "Val Loss: 0.8288, Val ACC cond: 50.00%\n",
      "Epoch 8, start\n",
      "Epoch 008, Train Loss: 0.7192, Timestamp: 2024-06-12 14:08:54,\n",
      "Val Loss: 0.6943, Val ACC cond: 50.00%\n",
      "Epoch 9, start\n",
      "Epoch 009, Train Loss: 0.6827, Timestamp: 2024-06-12 14:09:07,\n",
      "Val Loss: 0.7099, Val ACC cond: 50.00%\n",
      "Epoch 10, start\n",
      "Epoch 010, Train Loss: 0.6717, Timestamp: 2024-06-12 14:09:19,\n",
      "Val Loss: 0.6832, Val ACC cond: 50.00%\n",
      "Start training at: 2024-06-12 14:09:20\n",
      "Epoch 1, start\n",
      "Epoch 001, Train Loss: 1.1618, Timestamp: 2024-06-12 14:09:33,\n",
      "Val Loss: 0.8600, Val ACC cond: 50.00%\n",
      "Epoch 2, start\n",
      "Epoch 002, Train Loss: 0.7561, Timestamp: 2024-06-12 14:09:46,\n",
      "Val Loss: 0.8328, Val ACC cond: 50.00%\n",
      "Epoch 3, start\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "N_epoch = 10\n",
    "N_batch = 16\n",
    "lr = 0.0001\n",
    "\n",
    "main_path = os.getcwd()\n",
    "\n",
    "classifier_type = 'between_truth'\n",
    "\n",
    "os.chdir(classifier_type)\n",
    "\n",
    "# Get the current directory\n",
    "model_path = os.getcwd()\n",
    "\n",
    "# Find directories that match the pattern\n",
    "for folder in os.listdir(model_path):\n",
    "    if os.path.isdir(folder) and folder.startswith('s') and (folder.endswith('A') or folder.endswith('B')):\n",
    "        folder_path = os.path.join(model_path, folder)\n",
    "\n",
    "        # Change to the target directory\n",
    "        os.chdir(folder_path)\n",
    "        try:\n",
    "            # Run the main function\n",
    "            main(classifier_type, epochs=N_epoch, batch_size = N_batch, lr = lr)\n",
    "        finally:\n",
    "            # Change back to the original directory\n",
    "            os.chdir(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d75b6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "N_epoch = 10\n",
    "N_batch = 12\n",
    "lr = 0.001\n",
    "\n",
    "main_path = os.getcwd()\n",
    "\n",
    "classifier_type = 'between_comp'\n",
    "\n",
    "os.chdir(classifier_type)\n",
    "\n",
    "# Get the current directory\n",
    "model_path = os.getcwd()\n",
    "\n",
    "# Find directories that match the pattern\n",
    "for folder in os.listdir(model_path):\n",
    "    if os.path.isdir(folder) and folder.startswith('s') and (folder.endswith('A') or folder.endswith('B')):\n",
    "        folder_path = os.path.join(model_path, folder)\n",
    "\n",
    "        # Change to the target directory\n",
    "        os.chdir(folder_path)\n",
    "        try:\n",
    "            # Run the main function\n",
    "            main(classifier_type, epochs=N_epoch, batch_size = N_batch, lr = lr)\n",
    "        finally:\n",
    "            # Change back to the original directory\n",
    "            os.chdir(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c646fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "N_epoch = 5\n",
    "N_batch = 16\n",
    "lr = 0.0001\n",
    "\n",
    "main_path = os.getcwd()\n",
    "\n",
    "classifier_type = 'between_cond'\n",
    "\n",
    "os.chdir(classifier_type)\n",
    "\n",
    "# Get the current directory\n",
    "model_path = os.getcwd()\n",
    "\n",
    "# Find directories that match the pattern\n",
    "for folder in os.listdir(model_path):\n",
    "    if os.path.isdir(folder) and folder.startswith('s') and (folder.endswith('A') or folder.endswith('B')):\n",
    "        folder_path = os.path.join(model_path, folder)\n",
    "\n",
    "        # Change to the target directory\n",
    "        os.chdir(folder_path)\n",
    "        try:\n",
    "            # Run the main function\n",
    "            main(classifier_type, epochs=N_epoch, batch_size = N_batch, lr = lr)\n",
    "        finally:\n",
    "            # Change back to the original directory\n",
    "            os.chdir(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebf4ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_240319",
   "language": "python",
   "name": "dl_240319"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
