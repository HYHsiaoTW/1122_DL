{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d45535c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eason/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import random\n",
    "from pathlib import Path\n",
    "from timm.models.layers import trunc_normal_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f3348da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, file_path, path_prefix=\"\"):\n",
    "        self.path_prefix = path_prefix\n",
    "        full_file_path = path_prefix + file_path\n",
    "        with open(full_file_path, 'r') as file:\n",
    "            data = [line.strip().split() for line in file.readlines()]\n",
    "        \n",
    "        self.cond_label = {cond_label: idx for idx, cond_label in enumerate(set(row[1] for row in data))}\n",
    "        self.files = [(row[0], self.cond_label[row[1]]) for row in data]\n",
    "        random.shuffle(self.files)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, cond_label = self.files[idx]\n",
    "        full_img_path = self.path_prefix + img_path\n",
    "        \n",
    "        img = nib.load(full_img_path).get_fdata()\n",
    "        img = np.float32(img)\n",
    "        img = torch.from_numpy(img)\n",
    "        if img.ndim == 4 and img.shape[-1] == 1:\n",
    "            img = img.squeeze(-1)\n",
    "        img = img.unsqueeze(0)\n",
    "        cond_label = torch.tensor(cond_label, dtype=torch.long)\n",
    "        return img, cond_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14956db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LayerNorm(nn.Module):\n",
    "#     def __init__(self, normalized_shape, eps=1e-6, data_format=\"channels_last\"):\n",
    "#         super().__init__()\n",
    "#         self.weight = nn.Parameter(torch.ones(normalized_shape))\n",
    "#         self.bias = nn.Parameter(torch.zeros(normalized_shape))\n",
    "#         self.eps = eps\n",
    "#         self.data_format = data_format\n",
    "#         self.normalized_shape = (normalized_shape,)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         if self.data_format == \"channels_last\":\n",
    "#             return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n",
    "#         elif self.data_format == \"channels_first\":\n",
    "#             u = x.mean(1, keepdim=True)\n",
    "#             s = (x - u).pow(2).mean(1, keepdim=True)\n",
    "#             x = (x - u) / torch.sqrt(s + self.eps)\n",
    "#             x = self.weight[:, None, None, None] * x + self.bias[:, None, None, None]\n",
    "#             return x\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    r\"\"\" LayerNorm that supports two data formats: channels_last (default) or channels_first. \n",
    "    The ordering of the dimensions in the inputs. channels_last corresponds to inputs with \n",
    "    shape (batch_size, height, width, channels) while channels_first corresponds to inputs \n",
    "    with shape (batch_size, channels, height, width).\n",
    "    \"\"\"\n",
    "    def __init__(self, normalized_shape, eps=1e-6, data_format=\"channels_last\"):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(normalized_shape))\n",
    "        self.bias = nn.Parameter(torch.zeros(normalized_shape))\n",
    "        self.eps = eps\n",
    "        self.data_format = data_format\n",
    "        if self.data_format not in [\"channels_last\", \"channels_first\"]:\n",
    "            raise NotImplementedError \n",
    "        self.normalized_shape = (normalized_shape, )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.data_format == \"channels_last\":\n",
    "            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n",
    "        elif self.data_format == \"channels_first\":\n",
    "            u = x.mean(1, keepdim=True)\n",
    "            s = (x - u).pow(2).mean(1, keepdim=True)\n",
    "            x = (x - u) / torch.sqrt(s + self.eps)\n",
    "            x = self.weight[:, None, None] * x + self.bias[:, None, None]\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82f9e04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Block(nn.Module):\n",
    "#     def __init__(self, dim, drop_path=0., layer_scale_init_value=1e-6):\n",
    "#         super().__init__()\n",
    "#         # Depthwise 3D convolution\n",
    "#         # self.dwconv = nn.Conv3d(dim, dim, kernel_size=7, padding=3, groups=dim)\n",
    "#         self.dwconv = Dynamic_conv3d(dim, dim, kernel_size=7, padding=3, groups=dim)\n",
    "#         # Layer normalization for 3D (adjusting for channel dimension)\n",
    "#         self.norm = LayerNorm(dim, eps=1e-6)\n",
    "#         # Pointwise convolutions using linear layers\n",
    "#         self.pwconv1 = nn.Linear(dim, 4 * dim)\n",
    "#         self.act = nn.GELU()\n",
    "#         self.pwconv2 = nn.Linear(4 * dim, dim)\n",
    "#         # Layer scaling if it is utilized\n",
    "#         self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim)), \n",
    "#                                   requires_grad=True) if layer_scale_init_value > 0 else None\n",
    "#         self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         input = x\n",
    "#         x = self.dwconv(x)\n",
    "#         x = x.permute(0, 2, 3, 4, 1)  # Permute to bring channel to last\n",
    "#         x = self.norm(x)\n",
    "#         x = self.pwconv1(x)\n",
    "#         x = self.act(x)\n",
    "#         x = self.pwconv2(x)\n",
    "#         if self.gamma is not None:\n",
    "#             x = self.gamma * x\n",
    "#         x = x.permute(0, 4, 1, 2, 3)  # Permute back to normal\n",
    "\n",
    "#         x = input + self.drop_path(x)\n",
    "#         return x\n",
    "class Block(nn.Module):\n",
    "    r\"\"\" ConvNeXt Block. There are two equivalent implementations:\n",
    "    (1) DwConv -> LayerNorm (channels_first) -> 1x1 Conv -> GELU -> 1x1 Conv; all in (N, C, H, W)\n",
    "    (2) DwConv -> Permute to (N, H, W, C); LayerNorm (channels_last) -> Linear -> GELU -> Linear; Permute back\n",
    "    We use (2) as we find it slightly faster in PyTorch\n",
    "    \n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        drop_path (float): Stochastic depth rate. Default: 0.0\n",
    "        layer_scale_init_value (float): Init value for Layer Scale. Default: 1e-6.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, drop_path=0., layer_scale_init_value=1e-6):\n",
    "        super().__init__()\n",
    "        self.dwconv = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim) # depthwise conv\n",
    "        self.norm = LayerNorm(dim, eps=1e-6)\n",
    "        self.pwconv1 = nn.Linear(dim, 4 * dim) # pointwise/1x1 convs, implemented with linear layers\n",
    "        self.act = nn.GELU()\n",
    "        self.pwconv2 = nn.Linear(4 * dim, dim)\n",
    "        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim)), \n",
    "                                    requires_grad=True) if layer_scale_init_value > 0 else None\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"asdasd\")\n",
    "        input = x\n",
    "        x = self.dwconv(x)\n",
    "        x = x.permute(0, 2, 3, 1) # (N, C, H, W) -> (N, H, W, C)\n",
    "        x = self.norm(x)\n",
    "        x = self.pwconv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pwconv2(x)\n",
    "        if self.gamma is not None:\n",
    "            x = self.gamma * x\n",
    "        x = x.permute(0, 3, 1, 2) # (N, H, W, C) -> (N, C, H, W)\n",
    "\n",
    "        x = input + self.drop_path(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b242307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNeXt(nn.Module):\n",
    "    def __init__(self, in_chans=64, num_classes=4, \n",
    "                 depths=[3, 3, 9, 3], dims=[96, 192, 384, 768], drop_path_rate=0., \n",
    "                 layer_scale_init_value=1e-6, head_init_scale=1.,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.downsample_layers = nn.ModuleList() # stem and 3 intermediate downsampling conv layers\n",
    "        stem = nn.Sequential(\n",
    "            nn.Conv2d(in_chans, dims[0], kernel_size=5, stride=3),\n",
    "            LayerNorm(dims[0], eps=1e-6, data_format=\"channels_first\")\n",
    "        )\n",
    "        self.downsample_layers.append(stem)\n",
    "        for i in range(3):\n",
    "            downsample_layer = nn.Sequential(\n",
    "                    LayerNorm(dims[i], eps=1e-6, data_format=\"channels_first\"),\n",
    "                    nn.Conv2d(dims[i], dims[i+1], kernel_size=2, stride=2),\n",
    "            )\n",
    "            self.downsample_layers.append(downsample_layer)\n",
    "\n",
    "        self.stages = nn.ModuleList() # 4 feature resolution stages, each consisting of multiple residual blocks\n",
    "        dp_rates=[x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))] \n",
    "        cur = 0\n",
    "        for i in range(4):\n",
    "            stage = nn.Sequential(\n",
    "                *[Block(dim=dims[i], drop_path=dp_rates[cur + j], \n",
    "                layer_scale_init_value=layer_scale_init_value) for j in range(depths[i])]\n",
    "            )\n",
    "            self.stages.append(stage)\n",
    "            cur += depths[i]\n",
    "\n",
    "        self.norm = nn.LayerNorm(dims[-1], eps=1e-6) # final norm layer\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(dims[-1], 4096),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.GELU()\n",
    "        )\n",
    "\n",
    "        self.head = nn.Linear(4096, num_classes)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "        self.head.weight.data.mul_(head_init_scale)\n",
    "        self.head.bias.data.mul_(head_init_scale)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        for i in range(4):\n",
    "            # print(x.shape)\n",
    "            x = self.downsample_layers[i](x)\n",
    "            # print(x.shape)\n",
    "            x = self.stages[i](x)\n",
    "            # print(x.shape)\n",
    "        return self.norm(x.mean([-2, -1])) # global average pooling, (N, C, H, W) -> (N, C)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x = self.forward_features(x)\n",
    "        # print(x.shape)\n",
    "        x = self.fc_layers(x)\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f521ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, test_input, test_label, device):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Ensure test_input is a tensor and move it to the correct device\n",
    "    if not torch.is_tensor(test_input):\n",
    "        test_input = torch.tensor(test_input, dtype=torch.float, device=device)\n",
    "    else:\n",
    "        test_input = test_input.to(device)\n",
    "\n",
    "    # Ensure test_label is a tensor, add a batch dimension, and move to correct device\n",
    "    if isinstance(test_label, int):\n",
    "        test_label = torch.tensor([test_label], dtype=torch.long, device=device)\n",
    "    else:\n",
    "        test_label = test_label.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Perform model inference and get the predicted class\n",
    "        test_input = torch.squeeze(test_input, dim=1)\n",
    "        # test_input = test_input.permute(0, 2, 1, 3).contiguous() # channel - y\n",
    "        test_input = test_input.permute(0, 3, 2, 1).contiguous() # channel - z\n",
    "        outputs = model(test_input)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Check if the prediction is correct\n",
    "        correct = (predicted == test_label).item()  # Convert the result to Python boolean\n",
    "\n",
    "    return \"Correct\" if correct else \"Incorrect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00428464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, device, test_data=None, epochs=10):\n",
    "    model.train()\n",
    "    with open('training_log.txt', 'a') as log_file:\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            num_batches = 0\n",
    "            for img, cond in train_loader:\n",
    "                img = img.to(device)\n",
    "                cond = cond.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                img = torch.squeeze(img, dim=1)\n",
    "                # 將 H 和通道維度對調\n",
    "                # img = img.permute(0, 2, 1, 3).contiguous() # channel - y\n",
    "                img = img.permute(0, 3, 2, 1).contiguous() # channel - z\n",
    "                # print(img.shape)\n",
    "                cond_o = model(img)\n",
    "                loss_cond = criterion(cond_o, cond)\n",
    "                loss = loss_cond\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "                num_batches += 1\n",
    "            average_loss = total_loss / num_batches\n",
    "            current_utc = datetime.datetime.utcnow()\n",
    "            gmt8_time = current_utc + datetime.timedelta(hours=8)\n",
    "            current_time = gmt8_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            log_entry = f'Epoch {epoch+1:03}, Average Loss: {average_loss}, Timestamp: {current_time}\\n'\n",
    "            # Write the log entry to the file\n",
    "            log_file.write(log_entry)\n",
    "            # Test every 10 epochs\n",
    "            if (epoch + 1) % 10 == 0 and test_data is not None:\n",
    "                test_input, test_label = test_data\n",
    "                test_result = validate(model, test_input, test_label, device)\n",
    "                log_file.write(f\"Test at Epoch {epoch+1:03}: {test_result}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1c058e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(classifier, path_prefix=\"\", epochs=10, lr=0.001, batch=8):\n",
    "    # Configuration and Hyperparameters\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f'Using device: {device}')\n",
    "    \n",
    "    dataset_file = f'{classifier}+classify.txt'\n",
    "    \n",
    "    full_dataset = MRIDataset(dataset_file, path_prefix=path_prefix)\n",
    "    nc_cond = len(full_dataset.cond_label)\n",
    "    grand_results = []\n",
    "    \n",
    "    current_utc = datetime.datetime.utcnow()\n",
    "    gmt8_time = current_utc + datetime.timedelta(hours=8)\n",
    "    current_time = gmt8_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    # current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    start_time = f'Start training at: {current_time}'\n",
    "    print(start_time)\n",
    "    \n",
    "    for i in range(len(full_dataset)):\n",
    "        train_indices = list(range(len(full_dataset)))\n",
    "        train_indices.pop(i)  # Remove the test image index\n",
    "        test_index = i\n",
    "        \n",
    "        train_subset = Subset(full_dataset, train_indices)\n",
    "        test_input, test_label = full_dataset[test_index]\n",
    "\n",
    "        train_loader = DataLoader(train_subset, batch_size=batch, shuffle=True)\n",
    "            \n",
    "        model = ConvNeXt(in_chans=64, num_classes=nc_cond)\n",
    "        model = model.to(device)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        train(model, train_loader, criterion, optimizer, device, test_data=full_dataset[test_index], epochs=epochs)\n",
    "        result = validate(model, test_input, test_label, device)\n",
    "        grand_results.append(result)\n",
    "        \n",
    "        os.rename('training_log.txt', f'training_log+stim_{i+1:03}.txt')\n",
    "    \n",
    "    with open(f'{classifier}_final_results.log', 'w') as f:\n",
    "        correct_count = grand_results.count(\"Correct\")\n",
    "        total_tests = len(grand_results)\n",
    "        correct_percentage = (correct_count / total_tests) * 100 if total_tests > 0 else 0\n",
    "        for idx, result in enumerate(grand_results):\n",
    "            f.write(f\"Model {idx+1:03}: Result: {result}\\n\")\n",
    "        f.write(f\"Percentage of Correct Predictions: {correct_percentage:.2f}%\\n\")\n",
    "\n",
    "    print(f\"Percentage of Correct Predictions: {correct_percentage:.2f}%\")\n",
    "        \n",
    "    torch.save(model.state_dict(), f'{classifier}_epoch{epochs:03}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42001ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel = z\n",
      "Using device: cuda\n",
      "Start training at: 2024-06-16 20:03:57\n",
      "Percentage of Correct Predictions: 63.16%\n",
      "Using device: cuda\n",
      "Start training at: 2024-06-16 20:07:54\n",
      "Percentage of Correct Predictions: 73.17%\n",
      "Using device: cuda\n",
      "Start training at: 2024-06-16 20:12:12\n",
      "Percentage of Correct Predictions: 63.64%\n",
      "Using device: cuda\n",
      "Start training at: 2024-06-16 20:17:31\n",
      "Percentage of Correct Predictions: 87.80%\n",
      "Using device: cuda\n",
      "Start training at: 2024-06-16 20:21:48\n",
      "Percentage of Correct Predictions: 63.16%\n",
      "Using device: cuda\n",
      "Start training at: 2024-06-16 20:25:43\n",
      "Percentage of Correct Predictions: 62.22%\n",
      "Using device: cuda\n",
      "Start training at: 2024-06-16 20:31:11\n",
      "Percentage of Correct Predictions: 79.49%\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "N_ep = 50\n",
    "N_batch = 8\n",
    "\n",
    "main_path = os.getcwd()\n",
    "classifier_type = './condition'\n",
    "os.chdir(classifier_type)\n",
    "\n",
    "folder_list = [folder for folder in os.listdir() if folder.startswith('s') and os.path.isdir(folder)]\n",
    "print(\"channel = z\")\n",
    "for folder in folder_list:\n",
    "    os.chdir(folder)\n",
    "    main(classifier_type, epochs=N_ep, batch=N_batch)\n",
    "    \n",
    "    # Return to the parent directory\n",
    "    os.chdir('..')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
