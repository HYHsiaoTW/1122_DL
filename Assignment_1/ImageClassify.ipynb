{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16babb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "from skimage.feature import hog\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.svm import SVC\n",
    "from cuml import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13d80213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths for saving intermediate data for each feature extraction method\n",
    "feature_methods = ['hog', 'sift', 'edge', 'color_histogram']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aa00eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction method\n",
    "def extract_hog_features(image):\n",
    "    # Convert the image to grayscale\n",
    "    if image is None or image.size == 0:\n",
    "        raise ValueError(\"Input image is empty\")\n",
    "    # Ensure the image is in the correct format (8-bit grayscale)\n",
    "    if len(image.shape) == 3:  # Color image\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    if image.dtype != np.uint8:\n",
    "        image = image.astype(np.uint8)\n",
    "    features, _ = hog(image, orientations=8, pixels_per_cell=(16, 16),\n",
    "                      cells_per_block=(1, 1), visualize=True)\n",
    "    return features.reshape(1, -1)  # Reshape for consistency\n",
    "\n",
    "def extract_sift_features(image):\n",
    "    # Convert the image to grayscale\n",
    "    if image is None or image.size == 0:\n",
    "        raise ValueError(\"Input image is empty\")\n",
    "    # Ensure the image is in the correct format (8-bit grayscale)\n",
    "    if len(image.shape) == 3:  # Color image\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    if image.dtype != np.uint8:\n",
    "        image = image.astype(np.uint8)\n",
    "        \n",
    "    sift = cv2.SIFT_create()\n",
    "    _, descriptors = sift.detectAndCompute(image, None)\n",
    "    if descriptors is None:\n",
    "        return np.zeros((1, 128))  # Ensure a vector is returned even if no features are detected\n",
    "    return descriptors\n",
    "\n",
    "def extract_edge_features(image):\n",
    "    # Convert the image to grayscale\n",
    "    if image is None or image.size == 0:\n",
    "        raise ValueError(\"Input image is empty\")\n",
    "    # Ensure the image is in the correct format (8-bit grayscale)\n",
    "    if len(image.shape) == 3:  # Color image\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    if image.dtype != np.uint8:\n",
    "        image = image.astype(np.uint8)\n",
    "    \n",
    "    # Apply Canny edge detection\n",
    "    edges = cv2.Canny(image, threshold1=100, threshold2=200)\n",
    "    # Flatten the edge image to a 1D array and then reshape for consistency\n",
    "    features = edges.flatten().reshape(1, -1)\n",
    "    return features\n",
    "\n",
    "def extract_color_histogram_features(image, bins=32):\n",
    "    # Initialize the color histogram\n",
    "    histogram = np.array([])\n",
    "    # For each color channel (B, G, R)\n",
    "    for i in range(image.shape[2]):\n",
    "        # Calculate histograms per channel and normalize\n",
    "        hist = cv2.calcHist([image], [i], None, [bins], [0, 256])\n",
    "        hist = cv2.normalize(hist, hist).flatten()\n",
    "        # Concatenate histograms into a single feature\n",
    "        histogram = np.concatenate([histogram, hist])\n",
    "    # Reshape for consistency\n",
    "    features = histogram.reshape(1, -1)\n",
    "    return features\n",
    "\n",
    "def create_bow_features(all_features, n_clusters=100):\n",
    "    # Flatten the list of features arrays to fit KMeans\n",
    "    # Ensure all features are of dtype float32 before fitting KMeans\n",
    "    all_features_flattened = np.vstack(all_features).astype(np.float32)  # Cast to float32 here\n",
    "    kmeans = MiniBatchKMeans(n_clusters=n_clusters, random_state=0).fit(all_features_flattened)\n",
    "    bow_features = []\n",
    "\n",
    "    # Create a histogram for each image's features\n",
    "    for features in all_features:\n",
    "        features = features.astype(np.float32)  # Ensure features are float32 before prediction\n",
    "        labels = kmeans.predict(features)\n",
    "        hist, _ = np.histogram(labels, bins=np.arange(n_clusters+1), density=True)\n",
    "        bow_features.append(hist)\n",
    "    return np.array(bow_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1468b064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and labels function\n",
    "def load_img(filename, lb_min=None, lb_max=None, sn_min=None, sn_max=None):\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    imgs, labels = [], []\n",
    "\n",
    "    for line in lines:\n",
    "        fn, label = line.strip().split(' ')\n",
    "\n",
    "        # Extract serial number from filename\n",
    "        serial_number = int(fn.split('_')[-1].split('.')[0])\n",
    "\n",
    "        # Convert label to integer\n",
    "        label = int(label)\n",
    "\n",
    "        # Check if the serial number and label are within specified ranges\n",
    "        if (sn_min is None or sn_min <= serial_number) and \\\n",
    "           (sn_max is None or serial_number <= sn_max) and \\\n",
    "           (lb_min is None or lb_min <= label) and \\\n",
    "           (lb_max is None or label <= lb_max):\n",
    "\n",
    "            img = cv2.imread(fn)\n",
    "            img = cv2.resize(img, (256, 256))\n",
    "            imgs.append(img)\n",
    "            labels.append(label)\n",
    "\n",
    "    imgs = np.asarray(imgs, np.float32)\n",
    "    labels = np.asarray(labels, np.int32)\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d3eb9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_data(feature_method):\n",
    "    # Define file paths\n",
    "    train_features_path = f'L{lb_max}N{sn_max}/train_features_{feature_method}.joblib'\n",
    "    test_features_path = f'L{lb_max}N{sn_max}/test_features_{feature_method}.joblib'\n",
    "    train_labels_path = f'L{lb_max}N{sn_max}/train_labels.joblib'\n",
    "    test_labels_path = f'L{lb_max}N{sn_max}/test_labels.joblib'\n",
    "    \n",
    "    if not os.path.exists(f'L{lb_max}N{sn_max}/'):\n",
    "        os.makedirs(f'L{lb_max}N{sn_max}/')\n",
    "    \n",
    "    train_features = []  # Correctly initialize train_features\n",
    "    test_features = []  # Correctly initialize test_features\n",
    "    \n",
    "    # Load or process images and features\n",
    "    if not os.path.exists(train_features_path) or not os.path.exists(test_features_path):\n",
    "        train_imgs, train_labels = load_img('train.txt', lb_min, lb_max,sn_min, sn_max)\n",
    "        test_imgs, test_labels = load_img('test.txt', lb_min, lb_max)\n",
    "        \n",
    "        # Feature extraction\n",
    "        if feature_method == 'hog':\n",
    "            train_features = [extract_hog_features(image) for image in train_imgs]\n",
    "            test_features = [extract_hog_features(image) for image in test_imgs]\n",
    "        elif feature_method == 'sift':\n",
    "            train_features = [extract_sift_features(image) for image in train_imgs]\n",
    "            test_features = [extract_sift_features(image) for image in test_imgs]\n",
    "        elif feature_method == 'edge':\n",
    "            train_features = [extract_edge_features(image) for image in train_imgs]\n",
    "            test_features = [extract_edge_features(image) for image in test_imgs]\n",
    "        elif feature_method == 'color_histogram':\n",
    "            train_features = [extract_color_histogram_features(image) for image in train_imgs]\n",
    "            test_features = [extract_color_histogram_features(image) for image in test_imgs]\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported feature extraction method: {feature_method}\")\n",
    "            \n",
    "        if feature_method in ['hog', 'edge','color_histogram']:\n",
    "            train_features = np.array(train_features)\n",
    "            test_features = np.array(test_features)\n",
    "\n",
    "            train_features = train_features.reshape(train_features.shape[0], -1)\n",
    "            test_features = test_features.reshape(test_features.shape[0], -1)\n",
    "        elif feature_method == 'sift':\n",
    "            # Create Bag of Words features\n",
    "            all_features = train_features + test_features\n",
    "            bow_features = create_bow_features(all_features, n_clusters=100)\n",
    "            train_features, test_features = np.split(bow_features, [len(train_features)])\n",
    "\n",
    "        # Save processed data\n",
    "        joblib.dump(train_features, train_features_path)\n",
    "        joblib.dump(test_features, test_features_path)\n",
    "        joblib.dump(train_labels, train_labels_path)\n",
    "        joblib.dump(test_labels, test_labels_path)\n",
    "    else:\n",
    "        # Load processed data\n",
    "        train_features = joblib.load(train_features_path)\n",
    "        test_features = joblib.load(test_features_path)\n",
    "        train_labels = joblib.load(train_labels_path)\n",
    "        test_labels = joblib.load(test_labels_path)\n",
    "\n",
    "    return train_features, test_features, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdaa7f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_models(feature_method):\n",
    "    train_features, test_features, train_labels, test_labels = process_and_save_data(feature_method)\n",
    "\n",
    "    # Convert lists to arrays and ensure correct shape and dtype\n",
    "    train_features = np.array(train_features, dtype=np.float32)\n",
    "    test_features = np.array(test_features, dtype=np.float32)\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model_filename = f\"L{lb_max}N{sn_max}/{feature_method}_{name}_model.joblib\"\n",
    "        metrics_filename = f\"L{lb_max}N{sn_max}/{feature_method}_{name}_metrics.txt\"\n",
    "        \n",
    "\n",
    "        # Check if the model has already been trained and saved\n",
    "        if os.path.exists(model_filename):\n",
    "            print(f\"Loading saved {name} model trained with {feature_method} features.\")\n",
    "            model = joblib.load(model_filename)\n",
    "        else:\n",
    "            print(f\"Training {name} model with {feature_method} features.\")\n",
    "            model.fit(train_features, train_labels)\n",
    "            joblib.dump(model, model_filename)\n",
    "\n",
    "        # Predict and evaluate\n",
    "        pred_labels = model.predict(test_features)\n",
    "        f1 = metrics.f1_score(test_labels, pred_labels, average='weighted')\n",
    "        accuracy = metrics.accuracy_score(test_labels, pred_labels)\n",
    "        print(f\"{feature_method} - {name} - F1 Score: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        # Save metrics\n",
    "        with open(metrics_filename, 'w') as f:\n",
    "            f.write(f\"F1 Score: {f1:.4f}\\n\")\n",
    "            f.write(f\"Accuracy: {accuracy:.4f}\\n\")\n",
    "        \n",
    "        # Append performance metrics to \"performances.txt\"\n",
    "        with open('performances.txt', 'a') as perf_file:\n",
    "            perf_file.write(f\"{feature_method}, {name}, {sn_max}, {lb_max}, F1-score, {f1:.4f}\\n\")\n",
    "            perf_file.write(f\"{feature_method}, {name}, {sn_max}, {lb_max}, Accuracy, {accuracy:.4f}\\n\")\n",
    "        \n",
    "        # Compare predictions with actual labels\n",
    "        comparison = (pred_labels == test_labels).astype(int) # 1 for correct, 0 for incorrect\n",
    "        \n",
    "        # Save detailed comparison in long-format data fashion\n",
    "        with open('predictions_detailed.txt', 'a') as f:\n",
    "            for actual, predicted, correct in zip(test_labels, pred_labels, comparison):\n",
    "                f.write(f\"{feature_method}, {name}, {sn_max}, {lb_max}, {actual}, {predicted}, {correct}\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37a1cb7d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved KNN model trained with sift features.\n",
      "sift - KNN - F1 Score: 0.0392, Accuracy: 0.0392\n",
      "Loading saved SVM model trained with sift features.\n",
      "sift - SVM - F1 Score: 0.0023, Accuracy: 0.0196\n",
      "Loading saved XGBoost model trained with sift features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/DL_240319/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [10:50:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1707159369174/work/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sift - XGBoost - F1 Score: 0.0392, Accuracy: 0.0588\n",
      "Loading saved KNN model trained with color_histogram features.\n",
      "color_histogram - KNN - F1 Score: 0.0261, Accuracy: 0.0392\n",
      "Loading saved SVM model trained with color_histogram features.\n",
      "color_histogram - SVM - F1 Score: 0.0928, Accuracy: 0.1176\n",
      "Loading saved XGBoost model trained with color_histogram features.\n",
      "color_histogram - XGBoost - F1 Score: 0.0588, Accuracy: 0.0784\n",
      "Loading saved KNN model trained with edge features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/DL_240319/lib/python3.11/site-packages/cupy/_creation/from_data.py:88: PerformanceWarning: Using synchronous transfer as pinned memory (1323565056 bytes) could not be allocated. This generally occurs because of insufficient host memory. The original error was: cudaErrorMemoryAllocation: out of memory\n",
      "  return _core.array(a, dtype, False, order, blocking=blocking)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge - KNN - F1 Score: 0.0008, Accuracy: 0.0196\n",
      "Loading saved SVM model trained with edge features.\n",
      "edge - SVM - F1 Score: 0.0361, Accuracy: 0.0784\n",
      "Loading saved XGBoost model trained with edge features.\n",
      "edge - XGBoost - F1 Score: 0.0079, Accuracy: 0.0392\n",
      "Loading saved KNN model trained with hog features.\n",
      "hog - KNN - F1 Score: 0.0025, Accuracy: 0.0196\n",
      "Loading saved SVM model trained with hog features.\n",
      "hog - SVM - F1 Score: 0.0732, Accuracy: 0.0980\n",
      "Loading saved XGBoost model trained with hog features.\n",
      "hog - XGBoost - F1 Score: 0.0425, Accuracy: 0.0588\n"
     ]
    }
   ],
   "source": [
    "sn_min = 0\n",
    "sn_max = 100\n",
    "lb_min = 0\n",
    "lb_max = 50\n",
    "models = {\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'SVM': SVC(kernel='linear'),\n",
    "    'XGBoost': XGBClassifier(tree_method='hist', device='cuda')}\n",
    "train_and_evaluate_models('sift')\n",
    "train_and_evaluate_models('color_histogram')\n",
    "train_and_evaluate_models('edge')\n",
    "train_and_evaluate_models('hog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbf3c4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved KNN model trained with sift features.\n",
      "sift - KNN - F1 Score: 0.0020, Accuracy: 0.0099\n",
      "Loading saved XGBoost model trained with sift features.\n",
      "sift - XGBoost - F1 Score: 0.0617, Accuracy: 0.0891\n",
      "Loading saved KNN model trained with color_histogram features.\n",
      "color_histogram - KNN - F1 Score: 0.0066, Accuracy: 0.0099\n",
      "Loading saved XGBoost model trained with color_histogram features.\n",
      "color_histogram - XGBoost - F1 Score: 0.0528, Accuracy: 0.0693\n"
     ]
    }
   ],
   "source": [
    "sn_min = 0\n",
    "sn_max = 100\n",
    "lb_min = 0\n",
    "lb_max = 100\n",
    "models = {\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'XGBoost': XGBClassifier(tree_method='hist', device='cuda')}\n",
    "train_and_evaluate_models('sift')\n",
    "train_and_evaluate_models('color_histogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc537d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved KNN model trained with sift features.\n",
      "sift - KNN - F1 Score: 0.0052, Accuracy: 0.0132\n",
      "Loading saved XGBoost model trained with sift features.\n",
      "sift - XGBoost - F1 Score: 0.0453, Accuracy: 0.0596\n",
      "Loading saved KNN model trained with color_histogram features.\n",
      "color_histogram - KNN - F1 Score: 0.0044, Accuracy: 0.0066\n",
      "Loading saved XGBoost model trained with color_histogram features.\n",
      "color_histogram - XGBoost - F1 Score: 0.0648, Accuracy: 0.0795\n"
     ]
    }
   ],
   "source": [
    "sn_min = 0\n",
    "sn_max = 100\n",
    "lb_min = 0\n",
    "lb_max = 150\n",
    "train_and_evaluate_models('sift')\n",
    "train_and_evaluate_models('color_histogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1973d40",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved KNN model trained with sift features.\n",
      "sift - KNN - F1 Score: 0.0192, Accuracy: 0.0250\n",
      "Loading saved XGBoost model trained with sift features.\n",
      "sift - XGBoost - F1 Score: 0.0278, Accuracy: 0.0400\n",
      "Loading saved KNN model trained with color_histogram features.\n",
      "color_histogram - KNN - F1 Score: 0.0083, Accuracy: 0.0100\n",
      "Loading saved XGBoost model trained with color_histogram features.\n",
      "color_histogram - XGBoost - F1 Score: 0.0353, Accuracy: 0.0500\n"
     ]
    }
   ],
   "source": [
    "sn_min = 0\n",
    "sn_max = 100\n",
    "lb_min = 0\n",
    "lb_max = 200\n",
    "train_and_evaluate_models('sift')\n",
    "train_and_evaluate_models('color_histogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86b6e11e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved KNN model trained with sift features.\n",
      "sift - KNN - F1 Score: 0.0157, Accuracy: 0.0392\n",
      "Loading saved XGBoost model trained with sift features.\n",
      "sift - XGBoost - F1 Score: 0.1059, Accuracy: 0.1373\n",
      "Loading saved KNN model trained with color_histogram features.\n",
      "color_histogram - KNN - F1 Score: 0.0327, Accuracy: 0.0392\n",
      "Loading saved XGBoost model trained with color_histogram features.\n",
      "color_histogram - XGBoost - F1 Score: 0.1307, Accuracy: 0.1961\n"
     ]
    }
   ],
   "source": [
    "sn_min = 0\n",
    "sn_max = 400\n",
    "lb_min = 0\n",
    "lb_max = 50\n",
    "train_and_evaluate_models('sift')\n",
    "train_and_evaluate_models('color_histogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa110ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved KNN model trained with sift features.\n",
      "sift - KNN - F1 Score: 0.0131, Accuracy: 0.0196\n",
      "Loading saved XGBoost model trained with sift features.\n",
      "sift - XGBoost - F1 Score: 0.0327, Accuracy: 0.0392\n",
      "Loading saved KNN model trained with color_histogram features.\n",
      "color_histogram - KNN - F1 Score: 0.0523, Accuracy: 0.0588\n",
      "Loading saved XGBoost model trained with color_histogram features.\n",
      "color_histogram - XGBoost - F1 Score: 0.0392, Accuracy: 0.0588\n"
     ]
    }
   ],
   "source": [
    "sn_min = 0\n",
    "sn_max = 200\n",
    "lb_min = 0\n",
    "lb_max = 50\n",
    "train_and_evaluate_models('sift')\n",
    "train_and_evaluate_models('color_histogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f3d1004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved KNN model trained with sift features.\n",
      "sift - KNN - F1 Score: 0.0065, Accuracy: 0.0196\n",
      "Loading saved XGBoost model trained with sift features.\n",
      "sift - XGBoost - F1 Score: 0.1046, Accuracy: 0.1176\n",
      "Loading saved KNN model trained with color_histogram features.\n",
      "color_histogram - KNN - F1 Score: 0.0314, Accuracy: 0.0588\n",
      "Loading saved XGBoost model trained with color_histogram features.\n",
      "color_histogram - XGBoost - F1 Score: 0.0405, Accuracy: 0.0588\n"
     ]
    }
   ],
   "source": [
    "sn_min = 0\n",
    "sn_max = 50\n",
    "lb_min = 0\n",
    "lb_max = 50\n",
    "train_and_evaluate_models('sift')\n",
    "train_and_evaluate_models('color_histogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26a68e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fa5cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_240319",
   "language": "python",
   "name": "dl_240319"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
